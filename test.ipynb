{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "stop_words = set(stopwords.words('english'))\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        @tiffanylue i know  i was listenin to bad habi...\n",
      "1        Layin n bed with a headache  ughhhh...waitin o...\n",
      "2                      Funeral ceremony...gloomy friday...\n",
      "3                     wants to hang out with friends SOON!\n",
      "4        @dannycastillo We want to trade with someone w...\n",
      "                               ...                        \n",
      "39995                                     @JohnLloydTaylor\n",
      "39996                       Happy Mothers Day  All my love\n",
      "39997    Happy Mother's Day to all the mommies out ther...\n",
      "39998    @niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...\n",
      "39999    @mopedronin bullet train from tokyo    the gf ...\n",
      "Name: content, Length: 40000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv('tweet_emotions.csv')\n",
    "print(data['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_processing(content):\n",
    "    content = content.lower()\n",
    "    content = re.sub(r\"https\\S+|www\\S+http\\S+\",'', content, flags=re.MULTILINE)\n",
    "    content = re.sub(r'\\@w+|\\#','', content)\n",
    "    content = re.sub(r'[^\\w\\s]','', content)\n",
    "    content_token = word_tokenize(content)\n",
    "    filtered_content = [w for w in content_token if not w in stop_words]\n",
    "    return \" \".join(filtered_content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.content = data['content'].apply(data_processing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0        tiffanylue know listenin bad habit earlier sta...\n",
      "1                   layin n bed headache ughhhhwaitin call\n",
      "2                            funeral ceremonygloomy friday\n",
      "3                                  wants hang friends soon\n",
      "4        dannycastillo want trade someone houston ticke...\n",
      "                               ...                        \n",
      "39995                                      johnlloydtaylor\n",
      "39996                               happy mothers day love\n",
      "39997    happy mothers day mommies woman man long youre...\n",
      "39998    niariley wassup beautiful follow peep new hit ...\n",
      "39999    mopedronin bullet train tokyo gf visiting japa...\n",
      "Name: content, Length: 40000, dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(data['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = PorterStemmer()\n",
    "def stemming(data):\n",
    "    content = [stemmer.stem(word) for word in data]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['content'] = data['content'].apply(lambda x: stemming(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '00 graduated', '000', '000 dunno', '000 httpplurkcompwxj54', '0003', '0003 im', '002', '006', '006 totally', '01', '01 final', '01 girls', '01 mm', '010', '010 050', '0128', '0128 morning', '01theone', '01theone looking']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.10/lib/python3.10/site-packages/sklearn/utils/deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "vect = TfidfVectorizer(ngram_range=(1,2)).fit(data['content'])\n",
    "feature_names = vect.get_feature_names()\n",
    "print(feature_names[:20])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.7 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
